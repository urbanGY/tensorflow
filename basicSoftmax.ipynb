{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2,1,1],[2,1,3,2],[3,1,3,4],[4,1,5,5],[1,7,5,5],[1,2,5,6],[1,6,6,6],[1,7,7,7]]\n",
    "y_data = [[0,0,1],[0,0,1],[0,0,1],[0,1,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0]]#one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, 4])#input 의 shape이 4\n",
    "y = tf.placeholder(\"float\", [None, 3])#output이 3개 즉, softmax의 input이자 output의 수\n",
    "nb_classes = 3 # softmax로 분류할 class가 3가지라는것\n",
    "w = tf.Variable(tf.random_normal([4, nb_classes]), name='weight')#4가 input 3이 output\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.softmax(tf.matmul(x,w)+b)#cost계산 전 softmax를 이용해 나온 output이 hypothesis의 최종 output이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(hypothesis), axis = 1))#cross entropy cost산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.8878841\n",
      "2000 0.1566062\n",
      "4000 0.09149958\n",
      "6000 0.06416177\n",
      "8000 0.049255557\n",
      "10000 0.039910384\n",
      "12000 0.033517595\n",
      "14000 0.028874833\n",
      "16000 0.025353014\n",
      "18000 0.02259158\n",
      "20000 0.020369146\n",
      "22000 0.018542401\n",
      "24000 0.017014796\n",
      "26000 0.01571859\n",
      "28000 0.014605049\n",
      "30000 0.01363818\n",
      "32000 0.012791023\n",
      "34000 0.012042534\n",
      "36000 0.011376343\n",
      "38000 0.01077993\n",
      "40000 0.010242756\n",
      "42000 0.009756433\n",
      "44000 0.009314025\n",
      "46000 0.008909897\n",
      "48000 0.008539291\n",
      "50000 0.008198252\n",
      "52000 0.007883344\n",
      "54000 0.007591571\n",
      "56000 0.007320661\n",
      "58000 0.0070684836\n",
      "60000 0.0068330467\n",
      "62000 0.0066125942\n",
      "64000 0.006405926\n",
      "66000 0.0062118946\n",
      "68000 0.0060291425\n",
      "70000 0.005856928\n",
      "72000 0.0056941696\n",
      "74000 0.0055401805\n",
      "76000 0.0053943847\n",
      "78000 0.0052560666\n",
      "80000 0.0051246556\n",
      "82000 0.004999526\n",
      "84000 0.004880467\n",
      "86000 0.0047669434\n",
      "88000 0.004658413\n",
      "90000 0.0045549697\n",
      "92000 0.004455898\n",
      "94000 0.004360895\n",
      "96000 0.004270094\n",
      "98000 0.0041828332\n",
      "100000 0.004099247\n",
      "102000 0.0040187016\n",
      "104000 0.003941483\n",
      "106000 0.0038670036\n",
      "108000 0.0037951279\n",
      "110000 0.0037264158\n",
      "112000 0.0036595594\n",
      "114000 0.0035953987\n",
      "116000 0.0035335247\n",
      "118000 0.0034733715\n",
      "120000 0.0034152388\n",
      "122000 0.0033593802\n",
      "124000 0.0033053285\n",
      "126000 0.0032529212\n",
      "128000 0.0032017394\n",
      "130000 0.0031523176\n",
      "132000 0.0031048334\n",
      "134000 0.003058563\n",
      "136000 0.0030134558\n",
      "138000 0.0029698573\n",
      "140000 0.0029271778\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:#새로운 문법!\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "#     a = sess.run(hypothesis, feed_dict = {x:[[1,11,7,9]]})\n",
    "#     print(a, sess.run(tf.arg_max(a,1))) hypothesis의 output중 가장 큰녀석 보여줌\n",
    "    \n",
    "    for step in range(140001):\n",
    "        sess.run(optimizer, feed_dict={x:x_data, y:y_data})\n",
    "        if step%2000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={x:x_data, y:y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
